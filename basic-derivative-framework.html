<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ln(x + 1)^2 >= ln(x)ln(x + 2)</title>
    <script>
        MathJax = {
            loader: {
            load: ['[custom]/xypic.js'],
            paths: {custom: 'https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/'}
          },
          tex: {
            packages: ['base', 'ams', 'xypic'],
            tags: 'none',
            inlineMath: [['$', '$'], ['\\(', '\\)']]
          }
        };
      </script><link
rel="stylesheet"
href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css"
/>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <template>
        <div class="dropdown-box">
            <h3 class="dropdown-box-title">
            </h3>
            <div class="dropdown-box-content"></div>
        </div>
    </template>
    <template>
        <div class="spoiler">
            <div class="spoiler-head"></div>
        </div>
    </template>

    <style>
        body {
            font-size: 20px; /* Adjust the font size to your preference */
        }
        img {
            max-width: 100%;
        }
        .MathJax, .overflow-hidden {
            overflow-x: auto;
            overflow-y: hidden;
        }
    </style>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>

    <div class="content">
        <h1>Creating a basic derivative framework for a basic FCNN framework</h1>
        The date is 12/5/2024 and I am having my school break which will be quite long as it is the break between middle school and high school.
        I am trying to review fully connected neural networks which is something that I have made many months prior.
        It seems like a useful tool to have here would be a basic derivative framework.
        The goal is to create objects that may represent derivatives of functions which takes in arrays and outputs arrays.
        The framework must also allow easy general chain-rule applications. 
        It will be able to represent derivatives of such functions in general, but it will also have specialized 
        objects to represent derivatives of certain types of functions that appear in the standard FCNN models more efficiently.
        <h2>General derivatives of multidimensional-array functions</h2>
        Note: BLA = best linear approximation
        <h3>Representation</h3>
        Given a function $F(A)$ which returns a multidimensional-array and takes in a multidimensional-array,
        how do you represent the derivative of such a function?
        The derivative is represented by an array of shape A.shape + F.shape which should be thought of as an array of shape A.shape of arrays of shape F.shape.
        Each element in depth len(A.shape), say in index $i$ (remember that this index is a tuple, not a single integer because it indexes a multidimensional-array),
        is an array of shape F.shape which represents how the best linear approximation of F changes as the $i$th element of A changes by 1.
        In other words, it is literally the derivative of F in terms of the $i$th element of the input of F.
        which is easier to manage because the input in that case would be a single real number.
        <br><br>
        This actually lines up as an obvious generalization of grads for vector-valued multivariable functions.
        If you think of such a function, the "grad" is a matrix. 
        This matrix can be thought of as a vector of vectors, or an array of arrays.
        Each $i$th element of this array is a vector which represents the best linear approximation of how the function changes as the $i$th element of it's input changes by exactly 1.
        In other words, it is literally the derivative of $i$th element of the input vector.
        <br><br>
        Notice that this sounds exactly the same as before, it's just that $i$ is a proper integer index of a 1-dimensional array rather than a tuple-index of a multidimensional-array.
        It's just that, in the grad case, there is the operations of basic matrix-matrix multiplication between grads to do chain-rule.
        You can also do directional derivatives by simply doing matrix-vector multiplication with the grad and a direction vector. 
        So we will be exploring on how to generalize that on the next section.
        <h3>Chain rule and "directional derivatives"</h3>
        You may have noticed since earlier that I have been describing derivatives
        as an object of the same type as the output of a function
        which represents how the best linear approximation of the function changes as the input changes by exactly 1.
        This is because it is the mindset that I have been using while thinking of all of this which has proven to be quite helpful.
        Now to generalize directional derivatives. Going back to the case of vector-valued vector functions, suppose you have the functions
        $\vec{f}(\vec{a})$ and $\vec{g}(\vec{b})$, then you are able to have $\nabla \vec{f}(\vec{a})$ and $\nabla \vec{g}(\vec{b})$
        which represent the grad matrix of these two functions at the point $\vec{a}$ and $\vec{b}$.
        For now, ignore $\vec{g}$, that will be used later for the generalization of grads, and focus on $\vec{f}$.
        We know that we can take the directional-derivative at $\vec{c}$ in the direction of $\vec{d}$ by simply doing
        $\nabla \vec{f}(\vec{c}) \cdot \vec{d}$ as a matrix-vector multiplication.
        <br><br>
        Remember the statement from the previous section that $\nabla \vec{f}(\vec{c})$ is a matrix
        such that each $i$th column-vector of the matrix represents how the best linear approximation of the function changes as the $i$th input changes by exactly one.
        Since matrix-vector multiplication is just multiplying each element of the vector with the corresponding column-vector of the matrix on the same index and then summing them up,
        you can represent $\nabla \vec{f}(\vec{c}) \cdot \vec{d}$
        as simply being the sum for all $i$ of how the best linear approximation of the function changes as the $i$th input of the function changes by exactly the $i$th element of $\vec{d}$.
        The last statement is the key for generalizing this.
        <br><br>
        Actually, calling this "directional-derivatives" is a bit restrictive. 
        With this representation, now we can actually interpret this as simply being how the best linear approximation of the function changes as the input vector changes by any arbitrary vector $\vec{d}$ 
        which does not need to have a magnitude of one. 
        Just picture a function in 3D and a tangent plane at some point, that tangent plane is called the best linear approximation of the function at that point because it matches the value and also it's derivative/speed-of-movement.
        You are able to get any point in that tangent plane to get how the best linear approximation of the function as the input changes in any way you want.
        This is useful because you can't really think of directions anymore for array functions, 
        and even in vector functions, this operation where you are multiplying the grad by a non-directional-vector will still be useful
        in interpreting chain rule for the array function generalization.
        So, in conclusion, the important key statement from the previous paragraph can be stated symbolically as, if we define V to be the grad which is $V = \nabla \vec{f}(\vec{c})$ and L to 
        be the final linear approximation as the input changes by the arbitrary vector $\vec{d}$ which means $L = V \cdot \vec{d}$ as:
        $L = \sum_{i} V_i \vec{d}_i$
        where the sum variable $i$ ranges over all possible indexes of the input $\vec{a}$ which is just ${1, ..., \text{len}(\vec{a})}$
        <br><br> 
        Going back to the case of array functions with $F(A)$ and an array $D$.
        From what we have covered just now, we can now get something that may be interpreted as
        how the best linear approximation of F changes as A changes by any arbitrary amount $D$.
        The $i$th index of the derivative of F at A represents how the best linear approximation of F changes at A
        as the input changes by exactly one. 
        This means, based on the same logic as before, you can get the best linear approximation of how F changes as it's input 
        changes by the entire array D by summing up, for all possible index $i$, of how the output of F changes as the $i$th input of F changes by exactly $D_i$
        Which is literally just summing up, for all i, the ith element of the derivative of F times the scalar that is on the ith element of D. 
        Therefore, if L is the linear approximation and V is the derivative of F at A, then:
        $L = \sum_{i} V_i D_i$ where the sum variable $i$ ranges over all possible (tuple) indexes of the input of $F$.
        And of course, this is very similar to the previous expression for vector-valued vector functions. This will be defined as multiplication between these two types of objects.
        <br><br>
        The next step is to finally generalize the chain-rule. 
        The thing about them is that even the vector function version can be easily stated in terms of the type of operation we did before which is a more unrestricted version of directional-derivatives.
        Again, we start from the vector function case and then generalize from there. we will use the two functions $\vec{f}(\vec{a})$ and $\vec{g}{\vec{b}}$ that we have defined earlier
        and then define a new composition function $\vec{g}(\vec{c}) = \vec{f}(\vec{g}(\vec{c}))$.
        The goal is to find $\nabla \vec{g}(\vec{c})$ which we actually already know is equal to
        $$\nabla \vec{h}(\vec{c}) = \nabla \vec{f}(\vec{g}(\vec{c})) \cdot \nabla \vec{g}(\vec{c})$$
        So we know that this expression is split into the multiplication of two matrices, $\nabla \vec{f}$ and $\nabla \vec{g}$.
        <!-- To make things easier, let's say that
        $\vec{J} = \nabla \vec{f}(\vec{g}(\vec{c}))$ and $\$-->
        This means the $i$th column vector of $\nabla h$ is equal to the $i$th column vector of $\nabla g$ times the matrix $\nabla f$.
        The $i$th column vector of $\nabla g$ represents how the best linear approximation of $g$ changes as the $i$th element of $c$ changes by exactly one
        and that column vector dotted by $\nabla f$ represents how the best linear approximation of $f$ changes as the input, $g$,
        changes by exactly that $i$th column vector which itself is how g changes as the $i$th element of c changes.
        To reiterate, the vector which represents how the BLA (best linear approximation) of h changes as the ith element of it's input changes
        is equal to how the BLA of f changes as the BLA of g changes in the way it would when the $i$th element of c changes.
        This is essentially saying that the vector which represents how the BLA of $h$, a composition of f and g,
        changes as the $i$th input changes by exactly one is lierally the composition of how the BLA of f and g changes as the $i$th input of $g$ changes.
        <br><br>
        I will try to describe this in another way assuming no knowledge of what $\nabla h$ is.
        As the ith element of c changes by exactly one, the output of the BLA of g changes by the ith column vector of the grad of g
        which means the way the output of the BLA of f changes (which is the same as h) 
        is equal to the ith column vector of g multiplied by the grad of f.
        Therefore that should be the ith column vector of the grad of h.
        <br><br>
        Following this logic, you can now generalize chain rule for multidimensional array functions.
        This time we will define the functions $F(A)$, $G(B)$, and $H(C) = F(G(C))$.
        Following the logic from before, as the ith (tuple) index of C changes by exactly one,
        G changes by the sub-array of the derivative of G in index $i$ which means
        F changes by the derivative of F times that sub-array.
        Where times is the operation of "directional derivatives" that we have defined before.
        <!-- Suppose you create the function $\vec{h}(\vec{c}) = \vec{f}(\vec{g}(\vec{c}))$, how do you interpret the process of getting
        $\nabla \vec{h}(\vec{c})$ which may help us for generalization.
        We know that $\nabla \vec{h}(\vec{c}) = \nabla \vec{f}(\vec{g}(\vec{c})) \cdot \nabla \vec{g}(\vec{c})$.
        Here is how we should interpret this:  -->
    <br><br>
    Yeah so that was a lot of stuff that was possibly mixed with a lot of hard to understand attempt at explaining. I will now summarize all of the concepts I talked about: <br>
    Interpretations of vector-valued multivariable functions concepts for generalization: <br>
    (1) The ith column vector of the grad of a function at some point P represents how the BLA of the function at P changes
        as the ith element of the input, P, changes by exactly one <br>
    (2) The unrestricted directional derivative of a function at a point P with the direction vector D
        represents how the BLA of the function at P changes as it's input moves by exactly the vector D.
        If the grad is G then this value may be symbolically represented as $\sum_i G_i D_i$
        (which is exactly what matrix-vector multiplication is with G_i being the ith column vector of G)
        which may be interpreted as the sum of how the output of the function changes as each input i
        changes by the value on $D_i$ <br> 
    (3) The process of getting the grad of the composition of the functions f and g can be interpreted as:
        The ith column vector of the grad of g represents how the BLA of g changes as the ith input of g changes
        by exactly one, which may then be dotted with the grad of f to get how the BLA of f changes as g changes
        by that amount meaning the final value of the ith column of g dotted by grad f may be interpreted as how
        the BLA of f changes as the ith input of c changes by exactly one which,
        if it is true, then according to (1) it must be the grad of f composed with g.
        In other words, if L is the grad of f composed with g, J is the grad of f and K is the grad of g, then symbolically:
        $L_i = \sum_j J \cdot K_i$ the indexing gets the ith column vector of the corresponding grad matrix.
        Each jth term in the sum represents how the BLA of f changes as the jth element of c changes by exactly one.<br>
    <br>
    Interpretations of multidimensional array functions that is generalized from the previous concepts: <br> 
    (1) The "grad" of a multidimensional function F(A) is a multidimensional array of shape A.shape + F.shape
        where the sub-array in depth len(A.shape) with index $i$ represents how the BLA of F changes
        as the input, A, changes in index $i$ by exaxctly one. <br>
    (2) The unrestricted "directional derivative" of a function at a point P with the input difference array being D
        is an array of the same shape as the output of the function which represents how the BLA of the function changes
        as it's input changes by exactly D. If the "multidimensional grad" is G then this value is $\sum_i G_i D_i$.
        The only difference from the previous case is that i is the index of a multidimensional, therefore it is a tuple rather than a single number.
        This is how the operation of multiplication is defined. <br>
    (3) Suppose we have the function F(A) and G(B), then H(C) = F(G(C)).
        The sub-array in depth len(B.shape) with index $i$ in the MDA (multidimensional array) grad of G
        represents how the BLA of G changes as the ith input of G changes by exactly one,
        then you can multiply (the operation on (2)) that sub-array by the grad of F to get how the BLA of F changes as
        it's input changes by exactly that sub-array which is also how much G changes as it's input in index i changes by exactly one.
        In other words, the way the BLA of H changes as the ith element of C changes is exactly how much the BLA of F changes as the BLA of G changes in the way it would when the ith element changes by exactly one.
        Therefore, the ith element of the grad of H, which by (1) is supposed to represent how the BLA of H changes as the ith input of H changes,
        is exactly equal to the operation on (2) applied to the grad of F and the ith element of the grad of G.
        Symbolically, if L is the grad of H, J is the grad of F and K if the grad of G, then:
        $L_i = \sum_j J \cdot K_j$. This is the same as the vector function case except that i is now the index of a multidimensional array.
        Each jth term in the sum represents how the BLA of F (or H) changes as the jth element of C changes by exactly one.<br>

    <h2>Derivative framework</h2>
    Now that we're done with that, it's time to finally make the derivative framework. 
    The idea is to have an abstract base class which is able to generally represent the derivative of any multidimensional array function.
    Then there will be subclasses which is going to represent specialized types of MDA function derivatives.
    The purpose of these specialized subclasses is for it to be able to store the derivatives
    in a more efficient way and do the chain rule more efficiently as well.
    For example, the derivative of an elementwise function can be stored in an array of the same shape as the input/output
    rather than an array that has the shape of both of those shapes combined.
    One of the subclasses of the abstract base class is going to be the general MDA function derivative class
    that is always going to store derivatives using the input.shape + output.shape array representation.
    Now for the chain-rule method, each specialized class will have it's own chain-rule method which must be able to accept
    an array of the same size as the function's input and another derivative object with the same output shape as the self's input shape.
    Each class' chain-rule method must be able to handle any specialized derivative representation.
    Anyway here are the code in Python: <br>
    <pre><code class="language-python">class derivative:
    def input_shape(self) -> int:
        raise NotImplementedError();
        # return self.array.shape[:self.input_depth];

    def output_shape(self) -> int:
        raise NotImplementedError();
        # return self.array.shape[self.input_depth + 1:];

    # how the output changes as the input in the index changes by 1
    def __getitem__(self, index: tuple):
        raise NotImplementedError();

    def to_ndarray(self):
        raise NotImplementedError();

    # multiply with a difference in input to get how the BLA changes as the input changes by div_input
    def mul_di(self, div_input):
        raise NotImplementedError();

    def compose(self, inner):
        raise NotImplementedError();
    </code></pre>
    Then the standard derivative class:
    <pre><code class="language-python">class standard_derivative(derivative):
        def __init__(self, array: np.ndarray, input_depth: int):
            self.array = array;
            self.input_depth = input_depth;
    
        @property
        def output_depth(self) -> int:
            return len(self.array.shape) - self.input_depth;
    
        def input_shape(self) -> int:
            return self.array.shape[:self.input_depth];
    
        def output_shape(self) -> int:
            return self.array.shape[self.input_depth + 1:];
    
        # how the output changes as the input in the index changes by 1
        def __getitem__(self, index: tuple):
            return self.array[*index];
    
        def to_ndarray(self):
            return self.array;
    
        # multiply with a difference in input to get how the BLA changes as the input changes by div_input
        def mul_di(self, div_input):
            r = np.arange(self.output_depth);
            return np.einsum(self.array, [*r, Ellipsis], div_input, [r], [Ellipsis]);
    
        def compose(self, inner):
            t = type(inner);
            if (t == standard_derivative):
                return np.einsum();
            elif (t == ew_derivative):
                pass;
            elif (t == matvec_mat_derivative):
                pass;
        </code></pre>
        The other specialized derivatives that we will need for FCNNs are derivatives of elementwise functions,
        and derivatives of matrix-vector multiplications. For the matrix-vector multiplication derivative,
        we will actually be thinking of it as the more general version we have described earlier.
        After that, we will need to think about what the most efficient way of representing the composition of these derivative types are.
        Before that, I will review the mathematical model of FCNNs.
        For the entire network there is the loss function $\mathcal{L}$,
        then for individual layers $F_i$ there is the activation function $\sigmoi_id$, the weights $w_i$ and biases $b_i$.
        Then there is the network function $N(x, w, b)$.
        Then there is the cost function which is the sum of the loss function for all of the data that is used for training.
        There is the list of data $x_i$ with the expected output $y_i$.
        So the cost function is literally just $C(x, y, w, b) = \sum_{i=1}^N \mathcal{L}(F(x_i, w, b), y_i)$
        The goal is to minimize C in terms of all the ws and bs.

    </div>
    <script src="prism.js"></script>
</body>
</html>
